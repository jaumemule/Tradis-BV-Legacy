{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import io\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loop(coin_list_file):\n",
    "    first_date = pd.to_datetime(\"2018-06-01 00:01:00\", infer_datetime_format=True)\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client.aggregated\n",
    "    collection = db.binance_aggregation\n",
    "    \n",
    "    with open(coin_list_file) as f:\n",
    "        coins_tot = f.readlines()\n",
    "        coins_tot = [x.strip() for x in coins_tot]\n",
    "    \n",
    "    more = True\n",
    "    date = first_date\n",
    "    i=1\n",
    "    \n",
    "    while more:\n",
    "        print('pass number ' + str(i))\n",
    "        end_date = date + datetime.timedelta(days = 30)\n",
    "        data = list(collection.find({\"date\" : { '$gte': date, '$lt': end_date}}))\n",
    "        df = json_normalize(data) \n",
    "        \n",
    "        df = df.sort_values('date', ascending = True)\n",
    "        df.index = df['date']\n",
    "        df = df.drop([\"_id\", \"date\"], axis = 1).transpose()\n",
    "        temp_coins = [a for a in list(df.index) if a.split('.')[0] in coins_tot]\n",
    "        df = df[df.index.isin(temp_coins)]\n",
    "        df.to_csv(\"tusd_data_\" + str(i) + \".csv\")\n",
    "        \n",
    "        if df.shape[1]<10000:\n",
    "            more = False\n",
    "        \n",
    "        date = end_date\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_loop('tusd.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_csv(directory):\n",
    "    data_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-30035ce04382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tot_data_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"tot_data_\" + str(i) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_nan_check(directory, coin_list):\n",
    "   \n",
    "    path = os.getcwd()\n",
    "    data_path = os.path.join(path, 'data', directory)\n",
    "    \n",
    "    data_files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "    with open(coin_list) as f:\n",
    "        filtered_coins = f.readlines()\n",
    "    filtered_coins = [x.strip() for x in filtered_coins]\n",
    "    \n",
    "\n",
    "    i=1\n",
    "    for file in data_files:\n",
    "        df = pd.read_csv(os.path.join('data', directory, file),\n",
    "                         error_bad_lines=False,\n",
    "                         index_col=0)\n",
    "\n",
    "        temp_coins = [a for a in list(df.index) if a.split('.')[0] in filtered_coins]\n",
    "        df_filtered = df[df.index.isin(temp_coins)]\n",
    "        #df_filtered.to_csv('reduced_data_' + str(i) + '.csv')\n",
    "        nans = df_filtered.isnull().sum().sum()\n",
    "        print(\"The dimensions for set \" + str(file) + \" are \" + str(df_filtered.shape))\n",
    "        print(\"The number of missings is \" + str(nans))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions for set tusd_data_1.csv are (9, 43095)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_10.csv are (9, 42840)\n",
      "The number of missings is 76683\n",
      "The dimensions for set tusd_data_11.csv are (6, 43200)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_12.csv are (6, 42600)\n",
      "The number of missings is 212400\n",
      "The dimensions for set tusd_data_13.csv are (6, 43139)\n",
      "The number of missings is 43194\n",
      "The dimensions for set tusd_data_14.csv are (6, 37440)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_2.csv are (9, 42745)\n",
      "The number of missings is 18\n",
      "The dimensions for set tusd_data_3.csv are (9, 43200)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_4.csv are (9, 43200)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_5.csv are (9, 42990)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_6.csv are (9, 42780)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_7.csv are (9, 43200)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_8.csv are (9, 43200)\n",
      "The number of missings is 0\n",
      "The dimensions for set tusd_data_9.csv are (9, 43200)\n",
      "The number of missings is 0\n"
     ]
    }
   ],
   "source": [
    "data_nan_check('tusd_data', 'tusd.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tusd_data/tusd_data_13.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-05-27 00:01:00    6\n",
       "2019-05-27 00:02:00    6\n",
       "2019-05-27 00:03:00    6\n",
       "2019-05-27 00:04:00    6\n",
       "2019-05-27 00:05:00    6\n",
       "2019-05-27 00:06:00    6\n",
       "2019-05-27 00:07:00    6\n",
       "2019-05-27 00:08:00    6\n",
       "2019-05-27 00:09:00    6\n",
       "2019-05-27 00:10:00    6\n",
       "2019-05-27 00:11:00    6\n",
       "2019-05-27 00:12:00    6\n",
       "2019-05-27 00:13:00    6\n",
       "2019-05-27 00:14:00    6\n",
       "2019-05-27 00:15:00    6\n",
       "2019-05-27 00:16:00    6\n",
       "2019-05-27 00:17:00    6\n",
       "2019-05-27 00:18:00    6\n",
       "2019-05-27 00:19:00    6\n",
       "2019-05-27 00:20:00    6\n",
       "2019-05-27 00:21:00    6\n",
       "2019-05-27 00:22:00    6\n",
       "2019-05-27 00:23:00    6\n",
       "2019-05-27 00:24:00    6\n",
       "2019-05-27 00:25:00    6\n",
       "2019-05-27 00:26:00    6\n",
       "2019-05-27 00:27:00    6\n",
       "2019-05-27 00:28:00    6\n",
       "2019-05-27 00:29:00    6\n",
       "2019-05-27 00:30:00    6\n",
       "                      ..\n",
       "2019-05-31 23:51:00    6\n",
       "2019-05-31 23:52:00    6\n",
       "2019-05-31 23:53:00    6\n",
       "2019-05-31 23:54:00    6\n",
       "2019-05-31 23:55:00    6\n",
       "2019-05-31 23:56:00    6\n",
       "2019-05-31 23:57:00    6\n",
       "2019-05-31 23:58:00    6\n",
       "2019-05-31 23:59:00    6\n",
       "2019-06-01 00:00:00    0\n",
       "2019-06-01 00:01:00    0\n",
       "2019-06-01 00:02:00    0\n",
       "2019-06-01 00:03:00    0\n",
       "2019-06-01 00:04:00    0\n",
       "2019-06-01 00:05:00    0\n",
       "2019-06-01 00:06:00    0\n",
       "2019-06-01 00:07:00    0\n",
       "2019-06-01 00:08:00    0\n",
       "2019-06-01 00:09:00    0\n",
       "2019-06-01 00:10:00    0\n",
       "2019-06-01 00:11:00    0\n",
       "2019-06-01 00:12:00    0\n",
       "2019-06-01 00:13:00    0\n",
       "2019-06-01 00:14:00    0\n",
       "2019-06-01 00:15:00    0\n",
       "2019-06-01 00:16:00    0\n",
       "2019-06-01 00:17:00    0\n",
       "2019-06-01 00:18:00    0\n",
       "2019-06-01 00:19:00    0\n",
       "2019-06-01 00:20:00    0\n",
       "Length: 7220, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, :7220].isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-04-27 00:01:00</th>\n",
       "      <th>2019-04-27 00:02:00</th>\n",
       "      <th>2019-04-27 00:03:00</th>\n",
       "      <th>2019-04-27 00:04:00</th>\n",
       "      <th>2019-04-27 00:05:00</th>\n",
       "      <th>2019-04-27 00:06:00</th>\n",
       "      <th>2019-04-27 00:07:00</th>\n",
       "      <th>2019-04-27 00:08:00</th>\n",
       "      <th>2019-04-27 00:09:00</th>\n",
       "      <th>2019-04-27 00:10:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-05-26 23:51:00</th>\n",
       "      <th>2019-05-26 23:52:00</th>\n",
       "      <th>2019-05-26 23:53:00</th>\n",
       "      <th>2019-05-26 23:54:00</th>\n",
       "      <th>2019-05-26 23:55:00</th>\n",
       "      <th>2019-05-26 23:56:00</th>\n",
       "      <th>2019-05-26 23:57:00</th>\n",
       "      <th>2019-05-26 23:58:00</th>\n",
       "      <th>2019-05-26 23:59:00</th>\n",
       "      <th>2019-05-27 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 42600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [2019-04-27 00:01:00, 2019-04-27 00:02:00, 2019-04-27 00:03:00, 2019-04-27 00:04:00, 2019-04-27 00:05:00, 2019-04-27 00:06:00, 2019-04-27 00:07:00, 2019-04-27 00:08:00, 2019-04-27 00:09:00, 2019-04-27 00:10:00, 2019-04-27 00:11:00, 2019-04-27 00:12:00, 2019-04-27 00:13:00, 2019-04-27 00:14:00, 2019-04-27 00:15:00, 2019-04-27 00:16:00, 2019-04-27 00:17:00, 2019-04-27 00:18:00, 2019-04-27 00:19:00, 2019-04-27 00:20:00, 2019-04-27 00:21:00, 2019-04-27 00:22:00, 2019-04-27 00:23:00, 2019-04-27 00:24:00, 2019-04-27 00:25:00, 2019-04-27 00:26:00, 2019-04-27 00:27:00, 2019-04-27 00:28:00, 2019-04-27 00:29:00, 2019-04-27 00:30:00, 2019-04-27 00:31:00, 2019-04-27 00:32:00, 2019-04-27 00:33:00, 2019-04-27 00:34:00, 2019-04-27 00:35:00, 2019-04-27 00:36:00, 2019-04-27 00:37:00, 2019-04-27 00:38:00, 2019-04-27 00:39:00, 2019-04-27 00:40:00, 2019-04-27 00:41:00, 2019-04-27 00:42:00, 2019-04-27 00:43:00, 2019-04-27 00:44:00, 2019-04-27 00:45:00, 2019-04-27 00:46:00, 2019-04-27 00:47:00, 2019-04-27 00:48:00, 2019-04-27 00:49:00, 2019-04-27 00:50:00, 2019-04-27 00:51:00, 2019-04-27 00:52:00, 2019-04-27 00:53:00, 2019-04-27 00:54:00, 2019-04-27 00:55:00, 2019-04-27 00:56:00, 2019-04-27 00:57:00, 2019-04-27 00:58:00, 2019-04-27 00:59:00, 2019-04-27 01:00:00, 2019-04-27 01:01:00, 2019-04-27 01:02:00, 2019-04-27 01:03:00, 2019-04-27 01:04:00, 2019-04-27 01:05:00, 2019-04-27 01:06:00, 2019-04-27 01:07:00, 2019-04-27 01:08:00, 2019-04-27 01:09:00, 2019-04-27 01:10:00, 2019-04-27 01:11:00, 2019-04-27 01:12:00, 2019-04-27 01:13:00, 2019-04-27 01:14:00, 2019-04-27 01:15:00, 2019-04-27 01:16:00, 2019-04-27 01:17:00, 2019-04-27 01:18:00, 2019-04-27 01:19:00, 2019-04-27 01:20:00, 2019-04-27 01:21:00, 2019-04-27 01:22:00, 2019-04-27 01:23:00, 2019-04-27 01:24:00, 2019-04-27 01:25:00, 2019-04-27 01:26:00, 2019-04-27 01:27:00, 2019-04-27 01:28:00, 2019-04-27 01:29:00, 2019-04-27 01:30:00, 2019-04-27 01:31:00, 2019-04-27 01:32:00, 2019-04-27 01:33:00, 2019-04-27 01:34:00, 2019-04-27 01:35:00, 2019-04-27 01:36:00, 2019-04-27 01:37:00, 2019-04-27 01:38:00, 2019-04-27 01:39:00, 2019-04-27 01:40:00, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 42600 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
